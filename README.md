# Image-Caption-Generator--

ğŸ–¼ï¸ Image Caption Generator using Deep Learning (CNNâ€“RNN)

An end-to-end Image Caption Generation system built using Deep Learning, combining CNN-based feature extraction and RNN-based sequence modeling, with an interactive Gradio web interface for real-time caption generation.

ğŸ“Œ Project Overview

This project automatically generates natural language captions for input images.
It uses a pretrained CNN (VGG16) to extract visual features from images and an LSTM-based RNN to generate meaningful captions word by word.

The system is designed as:
A research/academic project
A GitHub portfolio project
A deployable demo using Gradio

ğŸš€ Key Features
ğŸ§  Deep Learningâ€“based caption generation
ğŸ–¼ï¸ Image feature extraction using VGG16
ğŸ” Sequence modeling with LSTM
ğŸ§¾ Tokenization & padding for text processing
ğŸŒ Interactive Gradio UI
ğŸ“¦ Modular and reusable code
âœ… Easy to run and extend

ğŸ—ï¸ Architecture
Input Image
     â†“
CNN (VGG16)
     â†“
Image Feature Vector
     â†“
Embedding Layer
     â†“
LSTM Decoder
     â†“
Generated Caption

ğŸ› ï¸ Tech Stack
Python 3
TensorFlow / Keras
NumPy
Pickle
Gradio
VGG16 (Pretrained CNN)

ğŸ“‚ Project Structure
â”œâ”€â”€ image_caption_generatorAIML.ipynb   # Model logic & caption generation
â”œâ”€â”€ gradio.ipynb                        # Gradio web interface
â”œâ”€â”€ tokenizer.pkl                       # Saved tokenizer
â”œâ”€â”€ model.h5                            # Trained captioning model
â”œâ”€â”€ README.md                           # Project documentation
â””â”€â”€ requirements.txt                    # Dependencies

ğŸ“Š Dataset Used
Flickr8k Dataset
~8,000 images

Each image has 5 human-annotated captions
Widely used for image captioning research
Note: Due to size constraints, the dataset is not included in this repository.

âš™ï¸ Installation & Setup
1ï¸âƒ£ Clone the Repository
git clone https://github.com/your-username/image-caption-generator.git
cd image-caption-generator

2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

3ï¸âƒ£ Required Files

Ensure the following files are present:
model.h5
tokenizer.pkl
(These are generated after training or provided separately.)

â–¶ï¸ Running the Project
ğŸ”¹ Run Caption Generator Notebook

Open and execute:
image_caption_generatorAIML.ipynb
ğŸ”¹ Launch Gradio Web App

Run:
gradio.ipynb


You will get a browser-based UI where you can upload an image and receive a caption instantly.

ğŸ§ª Sample Output
Input Image	Generated Caption
ğŸï¸ Image --	"a dog is running through the grass"

ğŸ§  Model Details
CNN: VGG16 (ImageNet pretrained, top layers removed)
RNN: LSTM
Embedding Dimension: 256
Optimizer: Adam
Loss Function: Categorical Crossentropy

ğŸ¯ Use Cases
Assistive technology for visually impaired users
Automated image tagging
Social media content generation
AI-based content understanding
Academic research and learning

ğŸ“Œ Limitations
Limited vocabulary (dataset dependent)
Performance constrained by dataset size
Works best on common objects/scenes
ğŸ”® Future Enhancements
ğŸ”„ Replace VGG16 with ResNet / EfficientNet
ğŸ§  Add Attention Mechanism
ğŸŒ Multilingual caption generation
â˜ï¸ Cloud deployment (Hugging Face / AWS)
ğŸ“± Mobile-friendly interface

ğŸ‘¨â€ğŸ’» Author
Vansh Garg
Computer Science Student | AIML & Data Science Enthusiast

Snehil Kanaujia 
Computer Science Student | AIML & Data Science Enthusiast

â­ Acknowledgements
Flickr8k Dataset creators
TensorFlow & Keras documentation
Gradio team

ğŸ“œ License
This project is intended for educational and research purposes.
