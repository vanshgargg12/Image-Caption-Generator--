# ğŸ–¼ï¸ Image Caption Generator using Deep Learning (CNN + LSTM)

An end-to-end **Image Caption Generation** system built using **Deep Learning**, combining **CNN-based feature extraction** and **LSTM-based sequence modeling**, with an interactive **Gradio web interface** for real-time caption generation.

---

## ğŸ“Œ Project Overview

This project automatically generates **natural language captions** for images.  
It uses a **pretrained VGG16 CNN** to extract visual features and an **LSTM-based language model** to generate meaningful captions word by word.

The project is designed to be:
- ğŸ“Š Academically strong (AIML / Deep Learning concepts)
- ğŸ’¼ Resume & GitHub worthy
- ğŸŒ Easily deployable using **Gradio**

---

## ğŸš€ Key Features

- CNN + RNN based Image Captioning
- Pretrained **VGG16** for image feature extraction
- **LSTM** for sequence prediction
- Tokenization & padding for text processing
- Interactive **Gradio UI**
- Clean and modular inference pipeline
- Easy to extend with new datasets or models

---

## ğŸ§  Model Architecture

Input Image
â†“
VGG16 (CNN)
â†“
Image Feature Vector
â†“
Embedding Layer
â†“
LSTM Network
â†“
Dense + Softmax
â†“
Generated Caption

yaml
Copy code

---

## ğŸ—‚ï¸ Project Structure

â”œâ”€â”€ image_caption_generatorAIML.ipynb # Model logic & caption generation
â”œâ”€â”€ gradio.ipynb # Gradio web interface
â”œâ”€â”€ tokenizer.pkl # Saved tokenizer
â”œâ”€â”€ model.h5 # Trained captioning model
â”œâ”€â”€ README.md # Project documentation

yaml
Copy code

---

## ğŸ“š Dataset

- **Flickr8k Dataset**
- Each image has **5 human-written captions**
- Used for training and evaluating the captioning model

> Dataset is not included due to size constraints.

---

## âš™ï¸ Technologies Used

- **Python 3**
- **TensorFlow / Keras**
- **NumPy**
- **Gradio**
- **VGG16 (Transfer Learning)**
- **LSTM (Sequence Modeling)**

---

## ğŸ§ª How It Works

1. Upload an image
2. Image is preprocessed and passed to **VGG16**
3. Extracted features are fed into the trained model
4. Caption is generated one word at a time
5. Final caption is displayed via Gradio UI

---

## â–¶ï¸ How to Run the Project

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/vanshgargg12/image-caption-generator.git
cd image-caption-generator
2ï¸âƒ£ Install Dependencies
bash
Copy code
pip install tensorflow numpy pillow gradio
3ï¸âƒ£ Run Gradio Interface
Open and run:

bash
Copy code
gradio.ipynb
OR run directly from notebook cells.

ğŸ–¥ï¸ Sample Output
pgsql
Copy code
Input Image: A dog running on the beach
Generated Caption: "a dog is running through the sand"
ğŸ“Œ Use Cases
Assistive technology for visually impaired users

Image search and indexing

Social media automation

Content moderation and tagging

AI-powered photo description tools

ğŸ“ˆ Future Improvements
Use ResNet/Inception instead of VGG16

Add BLEU score evaluation

Train on Flickr30k / MS-COCO

Deploy on Hugging Face Spaces

Add multilingual caption support

ğŸ‘¨â€ğŸ’» Author
Vansh Garg
Computer Science | DATA SCIENCE
UPES Dehradun

Snehil Kanaujia
Computer Science | AIML
UPES Dehradun


â­ Acknowledgements
Flickr8k Dataset

TensorFlow & Keras Documentation

Gradio Team

ğŸ“œ License
This project is licensed under the MIT License.
You are free to use, modify, and distribute it.

â­ If you like this project, donâ€™t forget to star the repository!
